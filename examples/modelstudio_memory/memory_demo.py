# -*- coding: utf-8 -*-
import asyncio
import logging
import os
import sys
import time
import uuid
from datetime import datetime
from typing import List, Tuple

from agentscope_runtime.tools.modelstudio_memory import (
    AddMemory,
    SearchMemory,
    ListMemory,
    DeleteMemory,
    CreateProfileSchema,
    GetUserProfile,
    GetUserProfileInput,
    Message,
    AddMemoryInput,
    SearchMemoryInput,
    ListMemoryInput,
    DeleteMemoryInput,
    CreateProfileSchemaInput,
    ProfileAttribute,
    MemoryAPIError,
    MemoryAuthenticationError,
    MemoryNotFoundError,
    MemoryValidationError,
)
from openai import AsyncOpenAI

# ===== é…ç½®æ—¥å¿—ï¼Œè¿‡æ»¤æ‰å†—é•¿çš„è°ƒè¯•ä¿¡æ¯ =====
# ä»ç¯å¢ƒå˜é‡è¯»å–æ—¥å¿—çº§åˆ«ï¼Œé»˜è®¤ä¸º WARNING
LOG_LEVEL = os.getenv("LOG_LEVEL", "WARNING").upper()
logging.basicConfig(
    level=getattr(logging, LOG_LEVEL, logging.WARNING),
    format=(
        "%(levelname)s: %(message)s"
        if LOG_LEVEL == "WARNING"
        else "%(asctime)s [%(levelname)s] %(name)s: %(message)s"
    ),
)

# ç‰¹åˆ«ç¦ç”¨æŸäº›ç»„ä»¶çš„è¯¦ç»†æ—¥å¿—ï¼ˆé™¤éæ˜ç¡®è®¾ç½®ä¸º DEBUGï¼‰
if LOG_LEVEL != "DEBUG":
    logging.getLogger("agentscope_bricks").setLevel(logging.WARNING)
    logging.getLogger("httpx").setLevel(logging.WARNING)
    logging.getLogger("httpcore").setLevel(logging.WARNING)


def require_env(name: str) -> str:
    value = os.getenv(name)
    if not value:
        print(
            f"[ERROR] Required environment variable not set: {name}",
            file=sys.stderr,
        )
        sys.exit(1)
    return value


def get_env(name: str, default: str) -> str:
    value = os.getenv(name, default)
    return value


def truncate(text: str, length: int = 120) -> str:
    if text is None:
        return ""
    if len(text) <= length:
        return text
    return text[: length - 3] + "..."


def print_section(title: str) -> None:
    bar_str = "=" * 70
    print(f"\n{bar_str}\n{title}\n{bar_str}")


def print_info(message: str) -> None:
    print(f"[system_info] {message}")


def print_warn(message: str) -> None:
    print(f"[warn] {message}")


def print_success(message: str) -> None:
    print(f"[success] {message}")


def print_error(message: str) -> None:
    print(f"[ERROR] {message}")


def format_api_error(error: MemoryAPIError) -> str:
    """æ ¼å¼åŒ– API é”™è¯¯ä¿¡æ¯ä»¥ä¾¿æ˜¾ç¤º"""
    parts = []

    # æå–é”™è¯¯æ¶ˆæ¯ä¸»ä½“ï¼ˆä¸åŒ…æ‹¬ __str__ æ–¹æ³•æ·»åŠ çš„é¢å¤–ä¿¡æ¯ï¼‰
    error_message = str(error).split(' | ', maxsplit=1)[0]
    parts.append(f"é”™è¯¯ä¿¡æ¯: {error_message}")

    if error.error_code:
        parts.append(f"é”™è¯¯ä»£ç : {error.error_code}")

    if error.status_code:
        parts.append(f"HTTP çŠ¶æ€ç : {error.status_code}")

    if error.request_id:
        parts.append(f"Request ID: {error.request_id}")

    return "\n          ".join(parts)


async def step_create_profile_schema(
    create_profile_schema: CreateProfileSchema,
) -> str:
    """åˆ›å»ºç”¨æˆ·ç”»åƒ Schema"""
    print_info("ç”¨æˆ·ç”»åƒ Schema ç”¨äºå®šä¹‰ç”¨æˆ·æœ‰å“ªäº›å­—æ®µï¼ˆå¦‚å¹´é¾„ã€çˆ±å¥½ï¼‰ã€‚")
    print("")

    payload = CreateProfileSchemaInput(
        name="ç”¨æˆ·ç”»åƒï¼ˆç¤ºä¾‹ï¼‰",
        description="ç”¨äºæ¼”ç¤ºçš„ç”¨æˆ·åŸºç¡€ç”»åƒ Schema",
        attributes=[
            ProfileAttribute(name="å¹´é¾„", description="ç”¨æˆ·å¹´é¾„"),
            ProfileAttribute(name="çˆ±å¥½", description="å…´è¶£åå¥½"),
        ],
    )

    # å±•ç¤ºç¤ºä¾‹å‚æ•°
    print_info("è¯·æ±‚å‚æ•°ï¼š")
    print_info(f"  Â· Schema åç§°ï¼š{payload.name}")
    print_info(f"  Â· Schema æè¿°ï¼š{payload.description}")
    print_info("  Â· å­—æ®µå®šä¹‰ï¼š")
    for idx, attr in enumerate(payload.attributes, start=1):
        print_info(f"      [{idx}] {attr.name} - {attr.description}")
    print("")

    result = await create_profile_schema.arun(payload)
    print_success("âœ“ å·²åˆ›å»ºç”¨æˆ·ç”»åƒ Schema")
    print_info(f"  Schema IDï¼š{result.profile_schema_id}")
    print_info(f"  è¯·æ±‚IDï¼š{result.request_id}")
    print("")

    return result.profile_schema_id


def example_messages() -> List[Message]:
    return [
        Message(
            role="user",
            content="æ¯å¤©ä¸Šåˆ9ç‚¹æé†’æˆ‘å–æ°´ï¼Œä¸‹åˆ3ç‚¹å¤ä¹ ç¬”è®°ã€‚",
        ),
        Message(role="assistant", content="å¥½çš„ï¼Œæˆ‘å·²ç»è®°å½•ä¸‹æ¥ã€‚"),
        Message(
            role="user",
            content="è¿˜æœ‰æ˜å¤©è®°å¾—æé†’æˆ‘ç»™è¯ºæˆè€å¸ˆä¹°ä¸ªç”Ÿæ—¥ç¤¼ç‰©ï¼Œ\
            è¯ºæˆè€å¸ˆä»Šå¹´30å²äº†ï¼Œæ¯”æˆ‘å¤§ä¸‰å²ã€‚æˆ‘ä»¬çš„çˆ±å¥½ç›¸åŒï¼Œ\
            ç»å¸¸ä¸€èµ·è¸¢çƒï¼Œæ‰€ä»¥æˆ‘æ‰“ç®—ç»™è¯ºæˆè€å¸ˆä¹°ä¸€ä¸ªç²¾ç¾çš„è¶³çƒ",
        ),
        Message(role="assistant", content="å¥½çš„ï¼Œæˆ‘æ˜å¤©ä¼šæé†’ä½ "),
    ]


async def step_add_memory(
    add_memory: AddMemory,
    end_user_id: str,
    profile_schema_id: str,
) -> List[str]:
    """æ·»åŠ å¯¹è¯è®°å¿†åˆ°è®°å¿†æœåŠ¡"""
    print_info("æˆ‘ä»¬å°†ä¸€æ®µå¯¹è¯æäº¤åˆ°è®°å¿†æœåŠ¡ï¼ŒæœåŠ¡ä¼šè‡ªåŠ¨å®Œæˆä¸¤ä»¶äº‹ï¼š")
    print_info("  1ï¸âƒ£  æŠ½å–å¹¶ä¿å­˜è®°å¿†æ¡ç›®ï¼ˆmemory nodesï¼‰")
    print_info("  2ï¸âƒ£  ä»å¯¹è¯ä¸­æå–ç”¨æˆ·ç”»åƒä¿¡æ¯ï¼ˆå¹´é¾„ã€çˆ±å¥½ç­‰ï¼‰")
    print("")

    now_ts = int(time.time())
    msgs = example_messages()
    payload = AddMemoryInput(
        user_id=end_user_id,
        messages=msgs,
        timestamp=now_ts,
        profile_schema=profile_schema_id,
        meta_data={
            "location_name": "æ­å·",
            "geo_coordinate": "120.1551,30.2741",
            "customized_key": "customized_value"
        },
    )

    # å±•ç¤ºç¤ºä¾‹å‚æ•°
    print_info("ğŸ“¥ è¯·æ±‚å‚æ•°ï¼š")
    print_info(f"  Â· ç”¨æˆ·IDï¼š{payload.user_id}")
    print_info(f"  Â· Profile Schema IDï¼š{truncate(profile_schema_id, 50)}")

    # æ ¼å¼åŒ–æ—¶é—´æˆ³
    timestamp_str = time.strftime(
        "%Y-%m-%d %H:%M:%S",
        time.localtime(payload.timestamp),
    )
    print_info(f"  Â· æ—¶é—´æˆ³ï¼š{timestamp_str}")
    print_info(f"  Â· å¯¹è¯æ¶ˆæ¯æ•°ï¼š{len(payload.messages)} æ¡")
    print("")

    print_info("ğŸ’¬ å¯¹è¯å†…å®¹ï¼ˆæ³¨æ„ç”»åƒä¿¡æ¯ï¼‰ï¼š")
    for idx, m in enumerate(payload.messages, start=1):
        role_icon = "ğŸ‘¤" if m.role == "user" else "ğŸ¤–"
        content_str = str(m.content)

        # çªå‡ºæ˜¾ç¤ºåŒ…å«ç”»åƒä¿¡æ¯çš„å¯¹è¯
        if "30å²" in content_str or "è¸¢çƒ" in content_str:
            print(f"  {role_icon} [{m.role}] {truncate(content_str, 100)} ğŸ¯")
        else:
            print(f"  {role_icon} [{m.role}] {truncate(content_str, 100)}")
    print("")
    print_info("  ğŸ¯ = åŒ…å«å¯æå–çš„ç”»åƒä¿¡æ¯ï¼ˆå¹´é¾„ã€çˆ±å¥½ï¼‰")
    print("")

    add_result = await add_memory.arun(payload)

    # è°ƒè¯•ï¼šæ‰“å°è¿”å›ç»“æœç±»å‹
    print_info(
        f"ğŸ” è°ƒè¯•ä¿¡æ¯ï¼šmemory_nodes ç±»å‹ = {type(add_result.memory_nodes)}",
    )

    # å…¼å®¹å¤„ç†ï¼šå¦‚æœ memory_nodes ä¸æ˜¯åˆ—è¡¨ï¼Œè½¬æ¢ä¸ºåˆ—è¡¨
    if isinstance(add_result.memory_nodes, list):
        memory_nodes_list = add_result.memory_nodes
    else:
        # å¦‚æœæ˜¯å•ä¸ªå¯¹è±¡ï¼ŒåŒ…è£…æˆåˆ—è¡¨
        memory_nodes_list = (
            [add_result.memory_nodes] if add_result.memory_nodes else []
        )

    node_ids = [
        n.memory_node_id for n in memory_nodes_list if n.memory_node_id
    ]

    if node_ids:
        print_success(f"âœ“ æˆåŠŸæ–°å¢ {len(node_ids)} æ¡è®°å¿†æ¡ç›®")
        print_info(f"  è¯·æ±‚IDï¼š{add_result.request_id}")
        print("")
        print_info("ğŸ“ ç”Ÿæˆçš„è®°å¿†æ¡ç›®ï¼š")
        print("")
        for idx, node in enumerate(memory_nodes_list, start=1):
            print(f"  [{idx}] Content: {truncate(node.content, 100)}")
            print(f"      ID: {node.memory_node_id}")
            print(f"      Event: {node.event}")
            if node.old_content:
                print(f"      Old content: {truncate(node.old_content, 100)}")

            if idx < len(memory_nodes_list):
                print("")
        print("")
    else:
        print_warn("âš  æœªè¿”å›ä»»ä½•è®°å¿†æ¡ç›® IDï¼Œç¨ååˆ é™¤æ­¥éª¤å°†è·³è¿‡ã€‚")

    return node_ids


async def step_list_memory(
    list_memory: ListMemory,
    end_user_id: str,
    page_num: int = 1,
    page_size: int = 10,
) -> List[str]:
    """åˆ—å‡ºç”¨æˆ·çš„æ‰€æœ‰è®°å¿†æ¡ç›®ï¼ˆåˆ†é¡µï¼‰"""
    print_info("åˆ—å‡ºè¯¥ç”¨æˆ·å½“å‰ä¿å­˜çš„æ‰€æœ‰è®°å¿†æ¡ç›®ï¼ˆåˆ†é¡µæŸ¥è¯¢ï¼‰ã€‚")
    print("")

    payload = ListMemoryInput(
        user_id=end_user_id,
        page_num=page_num,
        page_size=page_size,
    )

    # å±•ç¤ºç¤ºä¾‹å‚æ•°
    print_info("è¯·æ±‚å‚æ•°ï¼š")
    print_info(f"  Â· ç”¨æˆ·IDï¼š{payload.user_id}")
    print_info(f"  Â· é¡µç ï¼š{payload.page_num}")
    print_info(f"  Â· æ¯é¡µæ•°é‡ï¼š{payload.page_size}")
    print("")

    result = await list_memory.arun(payload)
    total_pages = (
        (result.total + result.page_size - 1) // result.page_size
        if result.page_size
        else 1
    )

    print_success(f"âœ“ åˆ—è¡¨è·å–æˆåŠŸ (è¯·æ±‚ID: {result.request_id})")
    print_info(
        f"ğŸ“Š åˆ†é¡µä¿¡æ¯ï¼šç¬¬ \
        {result.page_num}/{total_pages} é¡µï¼Œ\
        æ¯é¡µ {result.page_size} æ¡ï¼Œå…± {result.total} æ¡",
    )
    print("")

    if not result.memory_nodes:
        print_info("(å½“å‰é¡µæ— è®°å¿†æ¡ç›®)")
        return []

    print_info(f"ğŸ“ è®°å¿†æ¡ç›®åˆ—è¡¨ï¼ˆå½“å‰é¡µå…± {len(result.memory_nodes)} æ¡ï¼‰ï¼š")
    print("")

    existing_ids = []
    for idx, node in enumerate(result.memory_nodes, start=1):
        existing_ids.append(node.memory_node_id or "")
        print(f"  [{idx}] {truncate(node.content, 100)}")
        print(f"      ID: {node.memory_node_id}")
        if idx < len(result.memory_nodes):
            print("")

    print("")
    return [nid for nid in existing_ids if nid]


async def step_search_memory_with_llm(
    search_memory: SearchMemory,
    llm_client: AsyncOpenAI,
    end_user_id: str,
) -> Tuple[List[str], str]:
    """æ£€ç´¢è®°å¿†å¹¶ä½¿ç”¨å¤§æ¨¡å‹ç”Ÿæˆä¸ªæ€§åŒ–å›ç­”"""
    user_query = "ä»Šå¤©å’Œæ˜å¤©éœ€è¦æé†’æˆ‘åšä»€ä¹ˆï¼Ÿ"

    print_info(
        "æˆ‘ä»¬å°†ç”¨ä¸€ä¸ªè‡ªç„¶è¯­è¨€é—®é¢˜æ¥æ£€ç´¢ç›¸å…³è®°å¿†ï¼Œç„¶åè®©å¤§æ¨¡å‹åŸºäºè¿™äº›è®°å¿†ç”Ÿæˆä¸ªæ€§åŒ–å›ç­”ã€‚",
    )
    print("")

    # 1. æ£€ç´¢è®°å¿†
    print_info("ğŸ” ç¬¬ä¸€æ­¥ï¼šæ£€ç´¢ç›¸å…³è®°å¿†")
    payload = SearchMemoryInput(
        user_id=end_user_id,
        messages=[Message(role="user", content=user_query)],
        top_k=5,
        min_score=0,
    )

    print_info("æ£€ç´¢å‚æ•°ï¼š")
    print_info(f"  Â· ç”¨æˆ·IDï¼š{payload.user_id}")
    print_info(f"  Â· ç”¨æˆ·é—®é¢˜ï¼š{user_query}")
    print_info(f"  Â· è¿”å›æ¡æ•°ï¼štop_k={payload.top_k}")
    print_info(f"  Â· æœ€ä½åˆ†æ•°ï¼šmin_score={payload.min_score}")
    print("")

    search_result = await search_memory.arun(payload)
    print_success(f"âœ“ æ£€ç´¢å®Œæˆ (è¯·æ±‚ID: {search_result.request_id})")

    if not search_result.memory_nodes:
        print_warn("æœªæ‰¾åˆ°ç›¸å…³è®°å¿†æ¡ç›®")
        return [], user_query

    print_info(f"æ‰¾åˆ° {len(search_result.memory_nodes)} æ¡ç›¸å…³è®°å¿†ï¼š")
    print("")

    hit_ids = []
    for idx, node in enumerate(search_result.memory_nodes, start=1):
        hit_ids.append(node.memory_node_id or "")
        print(f"  [{idx}] {truncate(node.content, 100)}")
        print(f"      ID: {node.memory_node_id}")

    print("")
    print("â”€" * 70)
    print("")

    # 2. ä½¿ç”¨å¤§æ¨¡å‹ç”Ÿæˆå›ç­”
    print_info("ğŸ¤– ç¬¬äºŒæ­¥ï¼šåŸºäºæ£€ç´¢åˆ°çš„è®°å¿†ï¼Œè®©å¤§æ¨¡å‹ç”Ÿæˆä¸ªæ€§åŒ–å›ç­”")
    print("")

    context_lines = [
        f"- {node.content}" for node in search_result.memory_nodes
    ]
    system_prompt = (
        "ä½ æ˜¯ä¸€ååŠ©ç†ã€‚æ ¹æ®ä»¥ä¸‹æ£€ç´¢åˆ°çš„è®°å¿†å›ç­”ç”¨æˆ·é—®é¢˜ã€‚\n\n"
        + "è®°å¿†å†…å®¹ï¼š\n"
        + ("\n".join(context_lines) if context_lines else "(æ— æ£€ç´¢ç»“æœ)")
    )

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_query},
    ]

    model_name = "qwen-max"

    print_info(f"æ¨¡å‹ï¼š{model_name}ï¼ˆæµå¼è¾“å‡ºï¼‰")
    print_info(f"é—®é¢˜ï¼š{user_query}")
    print("")
    print_success("æ¨¡å‹å›ç­”ï¼š")
    print("")
    print("  ", end="")

    stream = await llm_client.chat.completions.create(
        model=model_name,
        messages=messages,
        stream=True,
        stream_options={"include_usage": True},
    )

    async for chunk in stream:
        if chunk.choices:
            delta = chunk.choices[0].delta
            if delta.content:
                print(delta.content, end="", flush=True)

    print("")
    print("")

    return [hid for hid in hit_ids if hid], user_query


async def step_get_user_profile(
    get_user_profile: GetUserProfile,
    schema_id: str,
    end_user_id: str,
) -> None:
    """è·å–å¹¶å±•ç¤ºç”¨æˆ·ç”»åƒä¿¡æ¯"""
    print_info("ğŸ¯ ç”¨æˆ·ç”»åƒåŠŸèƒ½å±•ç¤º")
    print("")
    print_info(
        "ğŸ’¡ è¯´æ˜ï¼šè®°å¿†æœåŠ¡ä¼šè‡ªåŠ¨ä»å¯¹è¯ä¸­æå–ç”¨æˆ·ä¿¡æ¯ï¼Œå¡«å……åˆ°ç”»åƒå­—æ®µä¸­ã€‚",
    )
    print_info("    ä¾‹å¦‚ï¼šä» 'è¯ºæˆè€å¸ˆä»Šå¹´30å²ï¼Œæ¯”æˆ‘å¤§ä¸‰å²' å¯æ¨æ–­å‡ºç”¨æˆ·27å²")
    print_info("          ä» 'æˆ‘ä»¬ç»å¸¸ä¸€èµ·è¸¢çƒ' å¯æ¨æ–­å‡ºç”¨æˆ·çˆ±å¥½æ˜¯è¶³çƒ")
    print("")

    payload = GetUserProfileInput(schema_id=schema_id, user_id=end_user_id)

    # å±•ç¤ºç¤ºä¾‹å‚æ•°
    print_info("ğŸ“¥ è¯·æ±‚å‚æ•°ï¼š")
    print_info(f"  Â· Schema IDï¼š{truncate(payload.schema_id, 50)}")
    print_info(f"  Â· ç”¨æˆ·IDï¼š{payload.user_id}")
    print("")

    result = await get_user_profile.arun(payload)
    print_success(f"âœ“ å·²è·å–ç”¨æˆ·ç”»åƒ (è¯·æ±‚ID: {result.request_id})")
    print("")

    # æ˜¾ç¤º Schema ä¿¡æ¯
    print_info("ğŸ“‹ Schema ä¿¡æ¯ï¼š")
    schema_name = result.profile.schema_name or "(æœªè®¾ç½®)"
    schema_desc = result.profile.schema_description or "(æœªè®¾ç½®)"
    print_info(f"  åç§°: {schema_name}")
    print_info(f"  æè¿°: {schema_desc}")
    print("")

    # æ˜¾ç¤ºç”¨æˆ·ç”»åƒ
    if result.profile.attributes:
        print_info(
            f"ğŸ‘¤ ç”¨æˆ·ç”»åƒï¼ˆå…± {len(result.profile.attributes)} ä¸ªå­—æ®µï¼‰ï¼š",
        )
        print("")

        for idx, attr in enumerate(result.profile.attributes, start=1):
            value_display = attr.value if attr.value else "(æš‚æœªæå–)"

            print_info(f"  [{idx}] {attr.name}")
            print_info(f"      å€¼: {value_display}")
            print_info(f"      ID: {attr.id}")

            # åˆ†éš”çº¿ï¼ˆæœ€åä¸€ä¸ªé™¤å¤–ï¼‰
            if idx < len(result.profile.attributes):
                print("")

        print("")

        # å¦‚æœæœ‰å­—æ®µè¢«å¡«å……ï¼Œæ·»åŠ è¯´æ˜
        has_values = any(attr.value for attr in result.profile.attributes)
        if has_values:
            print_success(
                "ğŸ’¡ æç¤ºï¼šä¸Šè¿°ç”»åƒä¿¡æ¯æ˜¯è®°å¿†æœåŠ¡è‡ªåŠ¨ä»å¯¹è¯ä¸­æå–çš„ï¼",
            )
        else:
            print_info(
                "ğŸ’¡ æç¤ºï¼šç”»åƒå­—æ®µæš‚æœªå¡«å……ï¼Œéšç€æ›´å¤šå¯¹è¯çš„ç§¯ç´¯ï¼Œä¼šé€æ­¥å®Œå–„ã€‚",
            )
        print("")
    else:
        print_info("(æš‚æ— ç”»åƒå­—æ®µ)")
        print("")


async def step_delete_memory(
    delete_memory: DeleteMemory,
    end_user_id: str,
    node_ids: List[str],
) -> None:
    """åˆ é™¤æŒ‡å®šçš„è®°å¿†æ¡ç›®"""
    print_info("åˆ é™¤åˆšæ‰æ–°å¢çš„è®°å¿†æ¡ç›®ï¼Œæ¼”ç¤ºæ•°æ®æ¸…ç†åŠŸèƒ½ã€‚")
    print("")

    if not node_ids:
        print_warn("âš  æ²¡æœ‰å¯åˆ é™¤çš„æ¡ç›®ï¼Œè·³è¿‡è¯¥æ­¥éª¤ã€‚")
        return

    # å±•ç¤ºç¤ºä¾‹å‚æ•°
    print_info("è¯·æ±‚å‚æ•°ï¼š")
    print_info(f"  Â· ç”¨æˆ·IDï¼š{end_user_id}")
    print_info(f"  Â· å¾…åˆ é™¤æ¡ç›®æ•°ï¼š{len(node_ids)}")
    print("")

    print_info(f"ğŸ—‘ï¸  æ­£åœ¨åˆ é™¤ {len(node_ids)} æ¡è®°å¿†...")
    print("")

    for idx, node_id in enumerate(node_ids, start=1):
        result = await delete_memory.arun(
            DeleteMemoryInput(user_id=end_user_id, memory_node_id=node_id),
        )
        print_success(
            f"  âœ“ [{idx}/{len(node_ids)}] å·²åˆ é™¤ï¼š{truncate(node_id, 50)}",
        )
        print_info(f"      è¯·æ±‚IDï¼š{result.request_id}")

    print("")
    print_success(f"âœ“ å…¨éƒ¨åˆ é™¤å®Œæˆï¼Œå…±åˆ é™¤ {len(node_ids)} æ¡è®°å¿†")


async def main() -> None:
    # Required envs
    dashscope_api_key = require_env("DASHSCOPE_API_KEY")
    
    # Generate random user ID if not set
    end_user_id = get_env("END_USER_ID", "")
    if not end_user_id:
        mmdd = datetime.now().strftime("%m%d")
        user_uuid = str(uuid.uuid4())[:8]
        end_user_id = f"modelstudio_memory_user_{mmdd}_{user_uuid}"
        print_info(f"ç”¨æˆ·ID: {end_user_id}")
        print("")
    
    llm_base_url = get_env(
        "LLM_BASE_URL",
        "https://dashscope.aliyuncs.com/compatible-mode/v1",
    )

    # Initialize components
    add_memory = AddMemory()
    search_memory = SearchMemory()
    list_memory = ListMemory()
    delete_memory = DeleteMemory()
    create_profile_schema = CreateProfileSchema()
    get_user_profile = GetUserProfile()
    
    # ä½¿ç”¨ OpenAI SDK åˆå§‹åŒ–å®¢æˆ·ç«¯
    llm_client = AsyncOpenAI(
        api_key=dashscope_api_key,
        base_url=llm_base_url,
    )

    try:
        print_section("Demo 0: Create Profile Schema")
        try:
            schema_id = await step_create_profile_schema(create_profile_schema)
        except (
            MemoryAPIError,
            MemoryAuthenticationError,
            MemoryValidationError,
        ) as e:
            print_error("âŒ åˆ›å»ºç”¨æˆ·ç”»åƒ Schema å¤±è´¥ï¼š")
            print_error(f"    {format_api_error(e)}")
            print_error(
                "\nğŸ’¡ å»ºè®®ï¼šè¯·æ£€æŸ¥ API Key æ˜¯å¦æ­£ç¡®ï¼Œæˆ–æŸ¥çœ‹ Request ID è”ç³»æŠ€æœ¯æ”¯æŒ",
            )
            return

        print_section("Demo 1: Add Memory")
        try:
            node_ids = await step_add_memory(
                add_memory,
                end_user_id,
                schema_id,
            )
        except (
            MemoryAPIError,
            MemoryAuthenticationError,
            MemoryValidationError,
        ) as e:
            print_error("âŒ æ·»åŠ è®°å¿†å¤±è´¥ï¼š")
            print_error(f"    {format_api_error(e)}")
            print_error(
                "\nğŸ’¡ å»ºè®®ï¼šè¯·æ£€æŸ¥å‚æ•°æ˜¯å¦æ­£ç¡®ï¼Œæˆ–æŸ¥çœ‹ Request ID è”ç³»æŠ€æœ¯æ”¯æŒ",
            )
            return

        # Wait for consistency
        print("")
        print_info("â³ ç­‰å¾…è®°å¿†ç”Ÿæˆï¼ˆ3ç§’ï¼‰...")
        await asyncio.sleep(3)
        print("")

        # 2. List memory
        print_section("Demo 2: List Memory")
        try:
            await step_list_memory(list_memory, end_user_id)
        except (
            MemoryAPIError,
            MemoryAuthenticationError,
            MemoryValidationError,
        ) as e:
            print_error("âŒ åˆ—å‡ºè®°å¿†å¤±è´¥ï¼š")
            print_error(f"    {format_api_error(e)}")
            # éå…³é”®æ­¥éª¤ï¼Œå¯ä»¥ç»§ç»­

        print_section("Demo 3: Search Memory + LLM Answer")
        try:
            _hits, _query = await step_search_memory_with_llm(
                search_memory,
                llm_client,
                end_user_id,
            )
        except (
            MemoryAPIError,
            MemoryAuthenticationError,
            MemoryValidationError,
        ) as e:
            print_error("âŒ æœç´¢è®°å¿†å¤±è´¥ï¼š")
            print_error(f"    {format_api_error(e)}")
            # éå…³é”®æ­¥éª¤ï¼Œå¯ä»¥ç»§ç»­

        # ç­‰å¾…ç”¨æˆ·ç”»åƒæå–å®Œæˆ
        print("")
        print_info("â³ ç­‰å¾…ç”¨æˆ·ç”»åƒæå–å®Œæˆï¼ˆ2ç§’ï¼‰...")
        print_info("   è®°å¿†æœåŠ¡æ­£åœ¨ä»å¯¹è¯ä¸­æå–ç”¨æˆ·ä¿¡æ¯ï¼ˆå¹´é¾„ã€çˆ±å¥½ç­‰ï¼‰...")
        await asyncio.sleep(2)
        print("")

        print_section("Demo 4: Get User Profile (å±•ç¤ºè‡ªåŠ¨æå–çš„ç”¨æˆ·ç”»åƒ)")
        try:
            await step_get_user_profile(
                get_user_profile,
                schema_id,
                end_user_id,
            )
        except (
            MemoryAPIError,
            MemoryAuthenticationError,
            MemoryValidationError,
            MemoryNotFoundError,
        ) as e:
            print_error("âŒ è·å–ç”¨æˆ·ç”»åƒå¤±è´¥ï¼š")
            print_error(f"    {format_api_error(e)}")
            # éå…³é”®æ­¥éª¤ï¼Œå¯ä»¥ç»§ç»­

        print_section("Demo 5: Delete Memory")
        try:
            await step_delete_memory(delete_memory, end_user_id, node_ids)
        except (
            MemoryAPIError,
            MemoryAuthenticationError,
            MemoryValidationError,
        ) as e:
            print_error("âŒ åˆ é™¤è®°å¿†å¤±è´¥ï¼š")
            print_error(f"    {format_api_error(e)}")
            # éå…³é”®æ­¥éª¤ï¼Œå¯ä»¥ç»§ç»­

        # Wait for consistency
        print("")
        print_info("â³ ç­‰å¾…åˆ é™¤ç”Ÿæ•ˆï¼ˆ2ç§’ï¼‰...")
        await asyncio.sleep(2)
        print("")

        print_section("Demo 6: List Memory Again (éªŒè¯åˆ é™¤)")
        try:
            await step_list_memory(list_memory, end_user_id)
        except (
            MemoryAPIError,
            MemoryAuthenticationError,
            MemoryValidationError,
        ) as e:
            print_error("âŒ åˆ—å‡ºè®°å¿†å¤±è´¥ï¼š")
            print_error(f"    {format_api_error(e)}")

        print("")
        print("=" * 70)
        print_success("ğŸ‰ æ‰€æœ‰æ¼”ç¤ºæ­¥éª¤å·²å®Œæˆï¼")
        print("=" * 70)

    finally:
        # æ¸…ç†èµ„æºï¼šå…³é—­æ‰€æœ‰ HTTP è¿æ¥
        print("")
        print_info("ğŸ”„ æ­£åœ¨æ¸…ç†èµ„æº...")
        await add_memory.close()
        await search_memory.close()
        await list_memory.close()
        await delete_memory.close()
        await create_profile_schema.close()
        await get_user_profile.close()
        await llm_client.close()
        print_info("âœ“ èµ„æºæ¸…ç†å®Œæˆ")


if __name__ == "__main__":
    asyncio.run(main())
